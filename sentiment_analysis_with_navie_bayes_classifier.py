# -*- coding: utf-8 -*-
"""sentiment analysis with navie bayes classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mntf3j3VY15Jm3Vv5ZUGaVS65CBzBIBc
"""

# importing necessary libraries
import pandas as pd
import numpy as np
import re
df = pd.read_csv("Sports.csv")
df.head()

df.shape

# Subset
df = df.sample(45)
# resetting index
df.reset_index(drop=True, inplace=True)
# sample dataset size
df.shape

# positive:1 , negative:0
df["Label"].replace({"positive":1, "negative":0}, inplace=True) # Replace "sentiment" with "Label"
df.head()

# functions to remove noise
# remove html tags
import re
def clean_html(text):
  clean = re.compile('<.*?>')
  return re.sub(clean, '', text)
# remove brackets
def remove_brackets(text):
 return re.sub("\[[^]]*\]", '', text)
# lower the cases
def lower_cases(text):
 return text.lower()
# remove special characters
def remove_char(text):
 pattern = r"[^a-zA-z0â€“9\s]"
 text = re.sub(pattern, '', text)
 return text
# remove noise(combine above functions)
def remove_noise(text):
 text = clean_html(text)
 text = remove_brackets(text)
 text = lower_cases(text)
 text = remove_char(text)
 return text
# call the function on predictors
df['Text']=df['Text'].apply(remove_noise) # Changed 'review' to 'Text'

from nltk.stem.porter import PorterStemmer
def stem_words(text):
 ps = PorterStemmer()
 stem_list = [ps.stem(word) for word in text.split()]
 text = ''.join(ps.stem(word) for word in text)

 return text
df['Text'] = df['Text'].apply(stem_words)

# importing from nlptoolkit library
import nltk
from nltk.corpus import stopwords

# Download the stopwords resource
nltk.download('stopwords')

# creating list of english stopwords
stopword_list = stopwords.words('english')

# removing the stopwords from review
def remove_stopwords(text):
    # list to add filtered words from review
    filtered_text = []
    # verify & append words from the text to filtered_text list
    for word in text.split(): # Removed extra indent
        if word not in stopword_list:
            filtered_text.append(word)
    # add content from filtered_text list to new variable
    clean_review = filtered_text[:]
    # emptying the filtered_text list for new review
    filtered_text.clear()
    return clean_review

df['Text']=df['Text'].apply(remove_stopwords)
df['Text']

# join back all words as single paragraph
def join_back(text):
    return ' '.join(text)

df['Text'] = df['Text'].apply(join_back)

# check if changes are applied
df.head()

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=800)
# vectorizing words and storing in variable X(predictor)
X = cv.fit_transform(df["Text"]).toarray()
# predictor
X
# X size
X.shape

# y size
y.shape

# train set and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tetrics import accuracy_score
# Naive Bayes Classifiers
gnb = GaussianNB()
mnb = MultinomialNB()
bnb = BernoulliNB()
# fitting and predicting
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_test)
mnb.fit(X_train, y_train)
y_pred_mnb = mnb.predict(X_test)
bnb.fit(X_train, y_train)
y_pred_bnb = bnb.predict(X_test)
# accuracy scores
print("Gaussian", accuracy_score(y_test, y_pred_gnb))
print("Multinomial", accuracy_score(y_test, y_pred_mnb))
print("Bernoulli", accuracy_score(y_test, y_pred_bnb))